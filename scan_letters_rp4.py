import cv2
import torch
import numpy as np
import time
from picamera2 import Picamera2
import math
import os

# üîπ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
from model import ArmenianLetterNet

model = ArmenianLetterNet()
model.load_state_dict(torch.load("armenian_letters_finetuned.pth", map_location="cpu"))
model.eval()

# üîπ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∏—Å—Ç–µ–º—ã
HEIGHT = 35  # –í—ã—Å–æ—Ç–∞ –ø–æ–ª—ë—Ç–∞ (30-40 –º)
CAMERA_ANGLE = 45  # –£–≥–æ–ª –Ω–∞–∫–ª–æ–Ω–∞ –∫–∞–º–µ—Ä—ã (–≥—Ä–∞–¥—É—Å—ã)
FOV_H = 62.2  # –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π —É–≥–æ–ª –æ–±–∑–æ—Ä–∞ –∫–∞–º–µ—Ä—ã
FOV_V = 48.8  # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π —É–≥–æ–ª –æ–±–∑–æ—Ä–∞ –∫–∞–º–µ—Ä—ã
RESOLUTION = (3280, 2464)  # –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∫–∞–º–µ—Ä—ã

# üîπ –§–æ–∫—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –∫–∞–º–µ—Ä—ã (–≤ –º–µ—Ç—Ä–∞—Ö)
FOCAL_LENGTH = HEIGHT * math.tan(math.radians(FOV_V / 2))

# üîπ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–∞–º–µ—Ä—ã
camera = Picamera2()
camera.preview_configuration.main.size = RESOLUTION
camera.preview_configuration.main.format = "RGB888"
camera.configure("preview")
camera.start()

# üîπ –§–∏–ª—å—Ç—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
confidence_threshold_low = 0.75   # üìå –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è —É—á—ë—Ç–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
confidence_threshold_high = 0.85  # üìå –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å, –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–π —Å—Ä–∞–∑—É —Ñ–∏–∫—Å–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
frame_buffer = []  # –ë—É—Ñ–µ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è

# üîπ –§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
def process_image(image):
    """ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –±—É–∫–≤ """
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)  # –ß—ë—Ä–Ω–æ-–±–µ–ª–æ–µ
    resized = cv2.resize(gray, (32, 32))  # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ —Ä–∞–∑–º–µ—Ä—É –º–æ–¥–µ–ª–∏
    tensor = torch.tensor(resized, dtype=torch.float32).unsqueeze(0).unsqueeze(0) / 255.0
    return tensor

# üîπ –§—É–Ω–∫—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞ –ø–∏–∫—Å–µ–ª–µ–π –≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
def pixel_to_coordinates(px, py, drone_lat, drone_lon):
    """ –ü–µ—Ä–µ–≤–æ–¥–∏—Ç –ø–∏–∫—Å–µ–ª–∏ –±—É–∫–≤—ã –≤ —Ä–µ–∞–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã """
    cx, cy = RESOLUTION[0] // 2, RESOLUTION[1] // 2  # –¶–µ–Ω—Ç—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è

    # üîπ –ú–µ—Ç—Ä—ã –Ω–∞ –ø–∏–∫—Å–µ–ª—å
    meters_per_pixel = (2 * HEIGHT * math.tan(math.radians(FOV_H / 2))) / RESOLUTION[0]

    # üîπ –°–º–µ—â–µ–Ω–∏–µ –±—É–∫–≤—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ü–µ–Ω—Ç—Ä–∞ –∫–∞–º–µ—Ä—ã
    dx = (px - cx) * meters_per_pixel
    dy = (py - cy) * meters_per_pixel * math.cos(math.radians(CAMERA_ANGLE))

    # üîπ –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
    lat_offset = dy / 111320  # 1 –≥—Ä–∞–¥—É—Å = ~111.32 –∫–º
    lon_offset = dx / (111320 * math.cos(math.radians(drone_lat)))

    return drone_lat + lat_offset, drone_lon + lon_offset

# üîπ –§—É–Ω–∫—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
def save_coordinates(letter, lat, lon, confidence):
    """ –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –±—É–∫–≤—ã –∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –Ω–∞ SD-–∫–∞—Ä—Ç—É """
    with open("/home/pi/letters_coordinates.txt", "a") as file:
        file.write(f"{letter},{lat},{lon},{confidence:.2f}\n")

# üîπ –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª
def scan_letters():
    """ –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –±—É–∫–≤ –∏ –∑–∞–ø–∏—Å—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç """
    global frame_buffer

    while True:
        frame = camera.capture_array()  # üì∑ –§–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä—É–µ–º
        tensor_image = process_image(frame)  # üñº –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        
        with torch.no_grad():
            output = model(tensor_image)  # üîç –†–∞—Å–ø–æ–∑–Ω–∞—ë–º –±—É–∫–≤—É
            probabilities = torch.nn.functional.softmax(output, dim=1)
            confidence, predicted_class = torch.max(probabilities, 1)

        confidence_value = confidence.item()
        letter = chr(1329 + predicted_class.item())

        # üîπ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        if confidence_value < confidence_threshold_low:
            print(f"‚ö†Ô∏è –°–ª–∞–±–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ ({confidence_value:.2f}) - –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º")
            continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–∞–±—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è

        # üîπ –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å 75-85%, –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–∞–¥—Ä–æ–≤
        if confidence_threshold_low <= confidence_value < confidence_threshold_high:
            frame_buffer.append((letter, confidence_value))

            if len(frame_buffer) >= 5:  # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º 5 –∫–∞–¥—Ä–æ–≤ –ø–æ–¥—Ä—è–¥
                avg_confidence = sum([c[1] for c in frame_buffer]) / len(frame_buffer)
                most_common_letter = max(set([c[0] for c in frame_buffer]), key=[c[0] for c in frame_buffer].count)
                
                if avg_confidence >= confidence_threshold_high:
                    print(f"‚úÖ –ù–∞–¥—ë–∂–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ ({most_common_letter}, {avg_confidence:.2f})")
                    frame_buffer.clear()  # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä
                else:
                    print(f"‚ö†Ô∏è –ù–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç ({avg_confidence:.2f}) - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    frame_buffer.clear()
                    continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–Ω–∞–¥—ë–∂–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è

        # üîπ –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤—ã—à–µ 85%, –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ
        if confidence_value >= confidence_threshold_high:
            drone_lat, drone_lon = 40.1792, 44.4991  # üîπ –ó–∞–≥–ª—É—à–∫–∞, –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ GPS!
            letter_lat, letter_lon = pixel_to_coordinates(RESOLUTION[0]//2, RESOLUTION[1]//2, drone_lat, drone_lon)

            save_coordinates(letter, letter_lat, letter_lon, confidence_value)
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –±—É–∫–≤–∞ {letter} ({confidence_value:.2f}) –Ω–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö {letter_lat}, {letter_lon}")

        # üîπ –≠–Ω–µ—Ä–≥–æ—Å–±–µ—Ä–µ–∂–µ–Ω–∏–µ ‚Äì –ø–∞—É–∑–∞ –º–µ–∂–¥—É —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        time.sleep(2)  

# üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
scan_letters()
