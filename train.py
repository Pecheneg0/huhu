import torch
import torch.nn as nn  # ‚úÖ –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from model import ArmenianLetterNet  # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
transform = transforms.Compose([
    transforms.Grayscale(),
    transforms.Resize((32, 32)),
    transforms.RandomRotation(30),  # ‚úÖ –ü–æ–≤–æ—Ä–æ—Ç—ã
    transforms.ColorJitter(brightness=0.3, contrast=0.3),  # ‚úÖ –Ø—Ä–∫–æ—Å—Ç—å/–∫–æ–Ω—Ç—Ä–∞—Å—Ç
    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # ‚úÖ –°–º–µ—â–µ–Ω–∏–µ
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
train_dataset = datasets.ImageFolder(root="dataset_generated_2", transform=transform)
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å
model = ArmenianLetterNet()
criterion = nn.CrossEntropyLoss()  # ‚úÖ –¢–µ–ø–µ—Ä—å nn –æ–ø—Ä–µ–¥–µ–ª—ë–Ω
optimizer = optim.Adam(model.parameters(), lr=0.001)

# –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
num_epochs = 10
for epoch in range(num_epochs):
    running_loss = 0.0
    correct = 0
    total = 0

    for images, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        correct += (predicted == labels).sum().item()
        total += labels.size(0)

    accuracy = 100 * correct / total
    print(f"üìä –≠–ø–æ—Ö–∞ {epoch+1}/{num_epochs} | –ü–æ—Ç–µ—Ä—è: {running_loss:.4f} | –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.2f}%")

print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
torch.save(model.state_dict(), "armenian_letters_model_2.pth")
print("‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞!")
